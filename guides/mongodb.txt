enable auth:
1.create super admin
use admin
db.createUser(
  {
    user: "myUserAdmin",
    pwd: "abc123",
    roles: [ { role: "root", db: "admin" } ]
  }
)

vi  /etc/mongod.conf 

security:
   authorization: enabled

For replication you have to setup one of below internal authentication if enabled authorization
a. Keyfiles
echo -e "my secret key" > mongo.keyfile
chmod 600 mongo.keyfile
chown mongod mongo.keyfile
To specify the keyfile, use the security.keyFile setting or --keyFile command line option.


b. x.509
security.clusterAuthMode and net.ssl.clusterFile if using a configuration file, or
--clusterAuthMode and --sslClusterFile command line options.

2. create db owner for specified db
mongo --port 27017 -u "myUserAdmin" -p "abc123" --authenticationDatabase "admin"
or 
use admin
db.auth("myUserAdmin", "abc123" )
then

use mydb
db.createUser(
  {
    user: "myTester",
    pwd: "xyz123",
    roles: [ { role: "dbOwner", db: "mydb" } ]
  }
)

db.createUser(
  {
    user: "myTester",
    pwd: "xyz123",
    roles: [ { role: "readWrite", db: "test" },
             { role: "read", db: "reporting" } ]
  }
)


Replication:
following example specifies the replica set name through the --replSet command-line option
You can also specify the security.replSetName in a configuration file. 

When you initialize the full replica set at once, every node should not have data.
When you turn an existing single node into a replica set, its data becomes the replica set data, and then adding additional nodes will replicate data to them wiping out their existing data.
What you should be doing is starting up the nodes, initializing the replica set and then creating users (only on the primary).

Use rs.initiate() on one and only one member of the replica set:
then change first member host name to ip before add other memebers because it always set the first member host name as os hostname and other memebers may not able to connect 
cfg = rs.conf()
cfg.members[0].host = "192.168.168.21:27017"
rs.reconfig(cfg) 

rs.reconfig(cfg, {force : true}) #When you use force : true, the version number in the replica set configuration increases significantly, by tens or hundreds of thousands.
# rs.reconfig() shell method can force the current primary to step down, which causes an election. When the primary steps down, the mongod closes all client connections. 

then add the rest members from primary:
rs.add("192.168.168.23")
use rs.addArb() to Arbiter which hold  no data but can elect a primary,if you want to convert a secondary node to arbiter you must stop and remove its data file first

You can force a replica set member to become primary by giving it a higher members[n].priority
members[n].priority value to 0, which means the member can never seek election as primary. 

to delete memeber from replication set:
a.when u have more than two memebers online
rs.remove()
b.when u have less than three online memebers you can't do rs.remove because if one server from two is down, the mongodb setting is configured to not allow any writes to the remaining online server. 
cfg = rs.conf()
cfg.members.splice(2,1)  ##从rs.conf()的memebers列表中id为2的元素，开始的第1个member，也就是id为2的member 
rs.reconfig(cfg) 

修改同步的目标
rs.syncFrom("hostname<:port>");
connect to primary
mongo "mongodb://172.18.91.147:27017,172.18.91.148:27017,172.18.91.149:27017/dbname?replicaSet=repname" -uusernmae -ppasswd

Write Concern:
Write concern describes the level of acknowledgement requested from MongoDB for write operations( insert, update, and delete, bulk for mongos) to a standalone mongod or to replica sets or to sharded clusters.
Write concern can include the following fields:
{ w: <value>, j: <boolean>, wtimeout: <number> }
the w option to request acknowledgement that the write operation has propagated to a specified number of mongod instances or to mongod instances with specified tags.
w can be <number>,"majority" and <tag set>
the j option to request acknowledgement that the write operation has been written to the journal
js can be true for false
the wtimeout option to specify a time limit to prevent write operations from blocking indefinitely.
This option specifies a time limit, in milliseconds is only applicable for w values greater than 1,wtimeout causes write operations to return with an error after the specified limit
With writeConcernMajorityJournalDefault set to false, MongoDB will not wait for w: "majority" writes to be durable before acknowledging the writes. As such, "majority" write operations could possibly roll back in the event of a loss of a replica set member.
writeConcernMajorityJournalDefault
Default: true if Replica Set protocolVersion is 1 and false if protocolVersion is 0

Convert replicati to standalone
1. dorp local db
use local
db.dropDatabase();
2.change configurations
comment out configuration file about if you have replication configuration
systemctl restart mongod 


The oplog (operations log) is a special capped collection that keeps a rolling record of all operations that modify the data stored in your databases. MongoDB applies database operations on the primary and then records the operations on the primary’s oplog. The secondary members then copy and apply these operations in an asynchronous process. All replica set members contain a copy of the oplog, in the local.oplog.rs collection, which allows them to maintain the current state of the database.
replication set的oplog相当于是mysql的binlog,里面记录了所有primary数据库的操作，并且具有幂等性，secondary通过复制和应用这些日志到自身数据库来达到同步的效果，每个replica set members都有一份oplog存在local.oplog.rs collection,oplog有大小限制，默认是5%的剩余空间,也就是说opelog只能保存一段时间的，所以当secondary离开集群时间过长，而primary上保存的oplog已经不能完全保证同步时，secondary再次启动就不能自动再加入集群了而变为stale状态。
变为stale状态的node必须要全部重新同步一次数据才能重新加入集群，相当于是新加入member到集群，有两种方式：
1.停止mongodb,删除dbPath文件，启动mongodb，这样会从primary全部同步数据，花费时间比较多。
2.从另外一个memebers拷贝dbPath文件，在这个过程中需要保证数据源的mongodb没有在运行,启动mongodb.(切记不能用mongodump备份数据，这种方式也适合添加新的memeber,只需在primary member再执行rs.add)

mongooplog 可以用来在线从远端pull oplog来应用到指定机器，默认只会pull过去24小时的oplog，可以通过--seconds指定时间:
mongooplog  --from mongodb0.example.net --host momgodb.local --seconds 86400

如果想在已有的备份上面追加新的记录，可以使用下面的方法：
1.mongodump -d local -c oplog.rs -oplog -o oplogD  #在primary备份oplog.rs collection
2.mongorestore -h host --port NNNN --oplogReplay --oplogLimit 1361497305:2789 oplogD  #在备份的collection上apply到指定timestamp的oplog
可以在primary的local db中通过db.oplog.rs.find()查找

opslog中ts的格式是$timestamp":{"t":1510307538,"i":107} ，t的值是epoch 到现在的时间可用date -d "@1510307538"转换成可读时间格式，也可以用date +'%s' -d'20171204 10:10:43'来转换可读时间格式到epoch 格式.i表示在这一秒内的操作次数
如果要想在mongodb中还原到特定的时间，那么必须满足一下几个条件：
1.开启replication
2.拥有定时的完整数据备份。mongodump --oplog --gzip --authenticationDatabase=admin -umongodbbackup -pP  mysqldump默认不会备份local 数据库
3.拥有oplog备份,在local中的oplog.rs collection,mongodump -d local -c oplog.rs -oplog -o oplogD --authenticationDatabase=admin -u -p
4.oplog备份中包含了完整备份后的所有操作，并且想要恢复的时间是在完整备份时间点之后(这就要求oplog size要足够大，否则就需要加快备份的频率)

当在本地恢复了完整备份后，如果你能知道是具体需要恢复到哪条语句,那么可以通过bsondump --type=json oplogD/local/oplog.rs.bson来找出具体的ts,也可以通过对比bsondump来对比备份的bson文件中最后的操作是否存在与oplog中，通过在oplog中查找备份collection的bson文件中最后一条记录的$oid是否存在来判断，也可以通过rs.printReplicationInfo()来查看oplog first event time来判断,同时还能通过ObjectId('5a0576d16b16e0f54d8d0542').getTimestamp()把oid转换为ts。
a ObjectId value 12-byte 的16进制ObjectId value consists of:
a 4-byte value representing the seconds since the Unix epoch,
a 3-byte machine identifier,
a 2-byte process id, and
a 3-byte counter, starting with a random value.

当确定你需要恢复的时间之后就执行：
mongorestore --host localhost --port 27017 --oplogReplay –oplogLimit 121232323:12 --dir ./oplogD


查看replication状态:
rs.printSlaveReplicationInfo()
查看Oplog的大小
rs.printReplicationInfo()

replSet error fatal couldn't query the local local.oplog.rs collection.  Terminating mongod after 30 seconds.
<timestamp> [rsStart] bad replSet oplog entry?

db = db.getSiblingDB("local")
db.oplog.rs.find().sort({$natural:-1}).limit(1)
db.oplog.rs.find({ts:{$type:17}}).sort({$natural:-1}).limit(1)
The first query returns the last document in the oplog, while the second returns the last document in the oplog where the ts value is a Timestamp. The $type operator allows you to select BSON type 17, is the Timestamp data type.
If the queries don’t return the same document, then the last document in the oplog has the wrong data type in the ts field.
To set the proper type for this value and resolve this issue, use an update operation that resembles the following:
db.oplog.rs.update( { ts: { t:1347982456000, i:1 } },
                    { $set: { ts: new Timestamp(1347982456000, 1)}})


mongodump以bson格式备份数据库或者collections,备份后的文件可以通过mongorestore来恢复：
mongodump  --db test
mongodump  --db test --collection collection
mongodump --host mongodb1.example.net --port 37017 --username user --password pass --out /opt/backup/mongodump-2011-10-24

mongorestore --collection people --db accounts dump/accounts/people.bson
mongorestore --host mongodb1.example.net --port 37017 --username user --password pass /opt/backup/mongodump-2011-10-24

mongoexport可以以json或者csv格式导出数据库中的某个collection，然后通过mongoimport导入:
mongoexport --db users --collection contacts --csv --fieldFile fields.txt --out /opt/backups/contacts.csv
mongoexport --db sales --collection contacts --out contacts.json --journal


可以通过下面的方式来导出所有的collections:
for c in `mongo --quiet $host:$port/$db --eval 'db.getCollectionNames()' | sed 's/,/ /g'`
do
    mongoexport --host $host --port $port -d $db -c $c > $c.json
done
mongoexport -d test -c records -q "{ a: { \$gte: 3 } }" --out exportdir/myRecords.json
mongoimport --db users --collection contacts --type csv --headerline --file /opt/backups/contacts.csv
如果没有指定-c 那么会以文件名为collectoin name
mongoimport --db users --type csv --headerline --file /opt/backups/contacts.csv

db.collectoin_name.find()来查询指定collectoin中所有的数据

mongodb-consistent-backup 可以用来备份并自动压缩，并支持多种方式上传，内部是用mongodbdump实现，所备份文件可以用mongorestore还原
mongodb-consistent-backup -H mongos1.example.com -P 27018 -u mongodb-consistent-backup -p s3cr3t -n prodwebsite -l /var/lib/mongodb-consistent-backup
mongorestore --host mongod12.example.com --port 27017 -u admin -p 123456 --oplogReplay --dir /var/lib/mongodb-consistent-backup/default/20170424_0000/rs0/dump
用户需要如下权限:
db.getSiblingDB("admin").createUser({
        user: "mongodbbackup",
        pwd: "PASSWORD-HERE",
        roles: [
                { role: "backup", db: "admin" },
                { role: "clusterMonitor", db: "admin" }
        ]
})

